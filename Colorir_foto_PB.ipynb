{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled3.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyP2BW9t8xri+z12HV0C1LnU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jefmamede/br-python-challenges/blob/master/Colorir_foto_PB.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tr0K8qd6CHZG"
      },
      "source": [
        "Colorindo uma foto antiga\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YltjFkSGCKag"
      },
      "source": [
        "# Importando as bibliotecas necessárias\n",
        "import numpy as np\n",
        "from google.colab.patches import cv2_imshow\n",
        "import cv2\n",
        "\n",
        "\n",
        "# Iniciando variáveis com o caminho dos arquivos\n",
        "protxt = \"model/colorization_deploy_v2.prototxt\"\n",
        "model = \"model/colorization_release_v2.caffemodel\"\n",
        "points = \"model/pts_in_hull.npy\"\n",
        "image = \"images/arvore.jpg\""
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MuffrBwwEmfX"
      },
      "source": [
        "# Usando a Open CV para ler o modelo através da função cv2.dnn.readNetFromCaffe\n",
        "print(\"[INFO] loading model...\")\n",
        "net = cv2.dnn.readNetFromCaffe(protxt, model)\n",
        "\n",
        "# O np.load() é usado porque o arquivo de ponto de cluster está no formato numpy. \n",
        "pts = np.load(points)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ldGhOxqFEiu"
      },
      "source": [
        "# Tratando cada ponto como uma convolução 1×1 e carregar para o modelo\n",
        "class8 = net.getLayerId(\"class8_ab\")\n",
        "conv8 = net.getLayerId(\"conv8_313_rh\")\n",
        "pts = pts.transpose().reshape(2, 313, 1, 1)\n",
        "net.getLayer(class8).blobs = [pts.astype(\"float32\")]\n",
        "net.getLayer(conv8).blobs = [np.full([1, 313], 2.606, dtype=\"float32\")]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iRu0s_hyFx7p"
      },
      "source": [
        "# Tratando imagem usando a Open CV\n",
        "image = cv2.imread(image)\n",
        "scaled = image.astype(\"float32\") / 255.0\n",
        "lab = cv2.cvtColor(scaled, cv2.COLOR_BGR2LAB)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IU3qVax0F9fE"
      },
      "source": [
        "# Na primeira linha, usamos cv2.imread para carregar a imagem. \n",
        "# Para o pré-processamento, na segunda linha fizemos um redimensionamento da intensidade dos pixels para o intervalo de [0,1]\n",
        "# Na terceira, convertemos o modelo de RGB para LAB.\n",
        "# 224×224, que é a dimensão exigida pelo modelo dos pesquisadores e depois vamos extrair o canal L\n",
        "resized = cv2.resize(lab, (224, 224))\n",
        "L = cv2.split(resized)[0]\n",
        "L -= 50"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jV8GUBxQGnmX"
      },
      "source": [
        "# O canal L será extraído como input para rede, para que ela seja capaz de prever os canais A e B.\n",
        "'print(\"[INFO] colorizing image...\")'\n",
        "net.setInput(cv2.dnn.blobFromImage(L))\n",
        "ab = net.forward()[0, :, :, :].transpose((1, 2, 0))\n",
        "\n",
        "# resize para retornar ao tamanho original\n",
        "ab = cv2.resize(ab, (image.shape[1], image.shape[0]))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d3i1t-luHC5b"
      },
      "source": [
        "# Extraindo o canal L da imagem original e concatenando com os canais A e B, da predição, formando assim a imagem colorida.\n",
        "L = cv2.split(lab)[0]\n",
        "colorized = np.concatenate((L[:, :, np.newaxis], ab), axis=2)\n",
        "\n",
        "# convertendo modelos, de LAB para RGB, e excluindo qualquer pixel que tenha ficado fora do intervalo especificado, [0,1]\n",
        "colorized = cv2.cvtColor(colorized, cv2.COLOR_LAB2BGR)\n",
        "colorized = np.clip(colorized, 0, 1)\n",
        "\n",
        "# retornando as intensidades dos pixels ao intervalo [0,255], pois durante o pré-processamento foram divididos por 255 e agora estamos multiplicando por 255\n",
        "colorized = (255 * colorized).astype(\"uint8\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LP-RSfzmIXOf"
      },
      "source": [
        "# Mostrando na tela as duas imagens a original e a colorida\n",
        "cv2.imshow(\"Original\", image)\n",
        "cv2.imshow(\"Colorized\", colorized)\n",
        "cv2.waitKey(0)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}